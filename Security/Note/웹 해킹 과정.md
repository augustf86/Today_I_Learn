# 웹 해킹 과정

## 웹 해킹을 하는 방법
1. 직관적으로 취약점이 있을 만한 부분을 찾아서 바로 취약점의 존재 여부를 확인한 후 그곳을 통해 침투를 시도하는 방법
2. 전반적으로 발견 가능한 모든 공격 표면을 찾아서 매트릭스를 작성한 후 하나씩 시도해보는 방법
    - 현재는 체크리스트 기반으로 모든 취약점을 점검하는 형태로 진행하는 경우가 많음


<br/><br/><br/>

## 시스템에 침투하는 일반적인 해킹 과정

### Step 1. 공격 대상 선정
일반적으로 방문자가 가장 많은 대표적인 웹 사이트를 주요 공격 대상으로 선정함
* 대중성이 있는 사이트 중 취약해 보이는 것으로 선정함 → 사용자가 많을수록 해킹으로 인한 파급력이 높기 때문
* 모의해킹 시에는 주로 공격 대상 목록을 사전에 선정함

<br/><br/>

### Step 2. 정보 수집
공격자가 원하는 목적을 달성하기 위해 공격 대상을 조사하는 과정에서 얻을 수 있는 모든 정보를 수집하는 것을 말함
* 웹 해킹에서의 정보 수집: 공격 대상이 보유하고 있는 외부 접점 중에서 웹 사이트를 통해 웹 애플리케이션을 개발할 때 사용한 언어, 웹 사이트 내 주요 공격 대상의 기능, 웹 서버의 종류 등을 알아보는 것
* **공격 대상의 특성과 취약한 표면을 찾음**
    - 공격 대상에 대한 정보가 많으면 많을수록 공격 벡터를 쉽게 파악할 수 있음
* 정보 수집의 과정
    1. 공격 대상 선정 후 먼저 대상 사이트에 접속함
    2. 사이트를 둘러보면서 홈페이지 파일의 확장자가 무엇인지 파악함
        - 파일 확장자를 통해 해당 시스템이 유닉스 기반인지 윈도우 기반인지 파악 → 웹 서버의 정보 수집과 취약점 분석을 위한 범위를 좁힐 수 있음
        - 예외 상황이 있을 수 있으므로 다각도로 정보를 수집해야 함
    3. 취약점이 가장 많이 발생하고 영향력이 큰 영역부터 조사하기 시작함
        - 영향력이 큰 취약점: 발견한 취약점으로 웹 서버의 권한을 획득하거나 내부의 중요한 데이터베이스에 접근할 수 있는 주요 취약점을 말함
        - 파일을 업로드할 수 있는 부분, 기본 정보를 얻을 수 있는지 등을 파악하여 분석함

<br/>

#### **정보 수집을 위한 다양한 방법**
* 자동화 도구를 이용한 정보 수집
    - 웹 사이트를 탐색하고 분석하기 위해 자동화 도구를 사용할 수 있음
    - 대표적인 자동화 도구: Burp Suite
        + Burp Suite의 [Target]-[Site map] 탭을 이용해 대상 사이트에서 방문했던 부분을 볼 수 있음
            - 각각을 클릭하면 디렉터리 구조, 파일 목록, HTML 소스코드 구조 등을 탐색할 수 있음

* 브라우저의 확장 기능을 이용한 정보 수집
    - 브라우저 확장 기능(개발자 도구)을 이용해 방문 사이트를 보는 동시에 사이트의 구조를 파악할 수 있음
    - 크롬, 엣지, 사파리 등의 개발자 도구의 Source(요소) 탭에서 웹 사이트의 구조를 쉽게 파악하고 항목 별 HTML 소스 위치를 확인할 수 있음

* 검색 엔진을 이용한 정보 수집
    - 웹 해킹을 할 때 가장 쉽게 많은 정보를 수집할 수 있음
    - 구글 검색 엔진을 활용하여 정보를 수집하는 방법
        | 검색 인수 | 설명|
        |---|------|
        | site: | 특정 도메인으로 지정한 사이트에 검색하려는 문자열이 포함된 사이트를 찾음 (**특정 사이트만 집중적으로 검색할 때 사용**) <br/> &nbsp;&nbsp; - EX: ```site:co.kr admin``` (co.kr 도메인이 있는 페이지에서 admin이라는 문자열을 찾음) |
        | filetype: | 특정 파일 타입에 한해 검색하려는 문자가 포함된 사이트를 찾음 <br/> &nbsp;&nbsp; - EX: ```filetype:txt 관리자 패스워드``` (파일 확장자가 txt이고 관리자와 패스워드라는 문자열이 포함된 파일을 검색함)  |
        | link: | 링크에 검색하려는 문자가 포함된 사이트를 찾음 <br/> &nbsp;&nbsp; - EX: ```link:korea.ac.kr``` (korea.ac.kr라는 주소의 링크를 가지고 있는 모든 웹 페이지를 검색함) |
        | cache: | 특정 검색어에 해당하는 캐시된 페이지를 보여줌 <br/> &nbsp;&nbsp; - EX: ```cache:korea.ac.kr``` (구글에 저장된 korea.ac.kr 페이지의 백업된 데이터를 검색할 수 있음) <br/> &nbsp;&nbsp; - 검색 엔진이 백업해둔 데이터에 취약점에 대한 정보가 남아있을 가능성이 있어 관리자는 반드시 검색 엔진에서 본인 사이트에 대해 검색해보아야 함 (노출되어사는 안되는 정보가 포함되어 있다면 검색 엔진 운영 회사에 정식으로 삭제를 요청함) |
        | intitle: | 📌 매우 유용한 기능: 페이지의 제목에 검색하려는 문자가 포함된 사이트를 찾음 <br/> &nbsp;&nbsp; - EX: ```intitle:index.of name size``` <br/> &nbsp;&nbsp; - 디렉토리 리스팅에 취약한 사이트를 검색할 때 사용함 (현재는 위험성이 많이 알려져서 보호 대책을 수립한 상태임) |
        | inurl: | 페이지의 URL에 검색하려는 문자가 포함된 사이트를 찾음 <br/> &nbsp;&nbsp; - EX: ```inurl:admin/login.asp.com``` (URL이 .com이면서 admin/login.asp 페이지가 있는 사이트를 검색함) <br/> &nbsp;&nbsp; - 특정 URL만을 대상으로 검색함 (```site:```와 유사한 기능을 수행)|
    - 검색 엔진을 피하는 방법(robots.txt 파일)
        + 웹 서버의 홈 디렉터리에 robots.txt 파일을 생성하면 검색할 수 없음
        + robots.txt 파일의 구성: User-agent와 Disallow로 구성됨
            - 예시
                ```
                User-agent: googlebot (구글 검색 엔진에서 검색하는 것을 막음)
                User-agent: * (모든 검색 로봇의 검색을 막음)

                Disallow: /admin/ (admin 디렉터리에 접근하지 못하도록 막음)
                ```

* 스캐닝 도구를 이용한 정보 수집
    - 웹 스캐닝 도구를 이용해 웹 서버의 종류와 버전, 디렉터리 정보나 중요한 파일 정보가 존재하는지 여부, 웹 서버 자체의 취약점 등을 검사함
        + 현재는 웹 스캐닝 도구를 많이 사용하지 않음
        + 일반적인 웹 스캐닝 도구의 원리
            1. 공격자는 대상 시스템(victim)에 HTTP Request(요청)을 보냄
            2. 대상 시스템(victim)은 해당 HTTP Request(요청)에 대한 응답 코드(Response Code)를 공격자에 전송함
            3. 공격자는 이 응답 코드를 보고 요청한 페이지가 존재하는지, 서버의 어느 부분이 취약한지 등을 파악할 수 있음
    - ⚠️ 주의사항
        + **현행법상 스캐닝만 해도 공격으로 간주하여 처벌을 받을 수 있기 때문**에 테스트용 컴퓨터나 허가받은 컴퓨터만을 대상으로 웹 스캐닝을 수행해야 함

<br/><br/>


### Step 3. 취약점 분석
정보 수집 단계에서 발견한 취약점에 대한 분석을 실시함
* 취약점이 발생한 기능이 무엇을 하는 기능인지, 사용하는 파일 형식은 무엇인지, 어떤 함수를 사용하고 있는지 등을 분석을 통해 파악함
* 취약점을 이용해 공격했을 때의 파급력을 계산함

<br/><br/>


### Step 4. 공격
취약점 분석 결과로 얻은 내용을 기반으로 공격을 수행함
* 발견한 취약점을 이용하여 공격 대상을 익스플로잇하기 위한 공격을 시작하며, 취약점 종류에 따라 공격 방법이 달라짐

<br/><br/>


### Step 5. Report, Defacement, 흔적 제거(Cleaning) 등의 후속 작업
* 모의 해킹 시 발견된 취약점과 취약점을 이용한 공격에 대한 보고서(Report)를 작성함
* 악의적인 공격일 경우 공격의 흔적을 제거(Cleaning)하는 작업을 수행함


<br/><br/><br/><br/>
### 🔖 출처
* 인터넷 해킹과 보안[4판], 김경곤, 한빛아카데미 _ Page 061 ~ 072 (Chapter 02-2. 일반적인 웹 해킹 과정)
